{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17bdc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c7bdde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                           Headline\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = pd.read_csv('../data/all-data.csv',encoding='ISO-8859-1', header=None)\n",
    "\n",
    "df.columns = ['Sentiment', 'Headline']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25ba8e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "neutral     2879\n",
      "positive    1363\n",
      "negative     604\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c5c5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # remove punctuation/numbers\n",
    "    return text\n",
    "\n",
    "df['News'] = df['Headline'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8fde3623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# df['label'] = le.fit_transform(df['Sentiment'])\n",
    "label_map = {'negative':0,'neutral':1,'positive':2}\n",
    "df['label'] = df['Sentiment'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1d2e067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 4846\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b01123cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df[['News','label']], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7414f140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Accuracy: 0.7567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.46      0.58       121\n",
      "     neutral       0.75      0.93      0.83       576\n",
      "    positive       0.75      0.52      0.61       273\n",
      "\n",
      "    accuracy                           0.76       970\n",
      "   macro avg       0.76      0.64      0.68       970\n",
      "weighted avg       0.76      0.76      0.74       970\n",
      "\n",
      "MultinomialNB Accuracy: 0.7289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.30      0.44       121\n",
      "     neutral       0.73      0.95      0.83       576\n",
      "    positive       0.71      0.44      0.55       273\n",
      "\n",
      "    accuracy                           0.73       970\n",
      "   macro avg       0.76      0.57      0.60       970\n",
      "weighted avg       0.74      0.73      0.70       970\n",
      "\n",
      "LinearSVC Accuracy: 0.7598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.62      0.67       121\n",
      "     neutral       0.80      0.85      0.83       576\n",
      "    positive       0.67      0.63      0.65       273\n",
      "\n",
      "    accuracy                           0.76       970\n",
      "   macro avg       0.73      0.70      0.71       970\n",
      "weighted avg       0.76      0.76      0.76       970\n",
      "\n",
      "RandomForest Accuracy: 0.7454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.42      0.53       121\n",
      "     neutral       0.74      0.95      0.83       576\n",
      "    positive       0.78      0.45      0.57       273\n",
      "\n",
      "    accuracy                           0.75       970\n",
      "   macro avg       0.74      0.61      0.65       970\n",
      "weighted avg       0.75      0.75      0.72       970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\Documents\\Summer Project\\stockPredictionApp\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:03:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.55      0.62       121\n",
      "     neutral       0.77      0.91      0.83       576\n",
      "    positive       0.74      0.55      0.63       273\n",
      "\n",
      "    accuracy                           0.76       970\n",
      "   macro avg       0.74      0.67      0.70       970\n",
      "weighted avg       0.76      0.76      0.75       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ## 3. TF–IDF + Traditional ML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_df['News'])\n",
    "X_test  = vectorizer.transform(test_df['News'])\n",
    "y_train = train_df['label']\n",
    "y_test  = test_df['label']\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'LinearSVC': LinearSVC(max_iter=10000),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, m in models.items():\n",
    "    m.fit(X_train, y_train)\n",
    "    preds = m.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, preds, target_names=label_map.keys()))\n",
    "    results[name] = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b222837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eddie\\Documents\\Summer Project\\stockPredictionApp\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.5482 - loss: 0.9752 - val_accuracy: 0.5954 - val_loss: 0.9299\n",
      "Epoch 2/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.5930 - loss: 0.9287 - val_accuracy: 0.5954 - val_loss: 0.9296\n",
      "Epoch 3/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.6022 - loss: 0.9244 - val_accuracy: 0.5954 - val_loss: 0.9289\n",
      "Epoch 4/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.6092 - loss: 0.9218 - val_accuracy: 0.5954 - val_loss: 0.9367\n",
      "Epoch 5/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.6012 - loss: 0.9283 - val_accuracy: 0.5954 - val_loss: 0.9301\n",
      "Epoch 6/10\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.5953 - loss: 0.9226 - val_accuracy: 0.5954 - val_loss: 0.9371\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5987 - loss: 0.9190\n",
      "LSTM Test Accuracy: 0.5938\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize and pad\n",
    "MAX_VOCAB = 10000\n",
    "MAX_LEN = 100\n",
    "EMB_DIM = 100\n",
    "\n",
    "tok = Tokenizer(num_words=MAX_VOCAB, oov_token='<OOV>')\n",
    "tok.fit_on_texts(train_df['News'])\n",
    "\n",
    "seq_train = tok.texts_to_sequences(train_df['News'])\n",
    "seq_test  = tok.texts_to_sequences(test_df['News'])\n",
    "\n",
    "X_train_seq = pad_sequences(seq_train, maxlen=MAX_LEN, padding='post')\n",
    "X_test_seq  = pad_sequences(seq_test, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "y_train_oh = pd.get_dummies(y_train).values\n",
    "y_test_oh  = pd.get_dummies(y_test).values\n",
    "\n",
    "# Build LSTM model\n",
    "gdlstm = Sequential([\n",
    "    Embedding(MAX_VOCAB, EMB_DIM, input_length=MAX_LEN),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "gdlstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "gdlstm.summary()\n",
    "\n",
    "# Train with early stopping\n",
    "early = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "gdlstm.fit(\n",
    "    X_train_seq, y_train_oh,\n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    callbacks=[early]\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, acc_lstm = gdlstm.evaluate(X_test_seq, y_test_oh)\n",
    "print(f\"LSTM Test Accuracy: {acc_lstm:.4f}\")\n",
    "results['LSTM'] = acc_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#credit: https://www.youtube.com/watch?v=JrtXX4cHgBI&ab_channel=GabrielAtkin\n",
    "#mainly for learning, XGboost still have slightly better accuracy\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7e56cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.760825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.759794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.756701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.745361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.728866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.593814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy\n",
       "4             XGBoost  0.760825\n",
       "2           LinearSVC  0.759794\n",
       "0  LogisticRegression  0.756701\n",
       "3        RandomForest  0.745361\n",
       "1       MultinomialNB  0.728866\n",
       "5                LSTM  0.593814"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "res_df = pd.DataFrame(\n",
    "    list(results.items()),\n",
    "    columns=['Model','Accuracy']\n",
    ").sort_values('Accuracy', ascending=False)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25273e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed91f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745313df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42cc299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9ebb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6072ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
